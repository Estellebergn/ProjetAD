{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2020 = pd.read_csv('data/2020.csv')\n",
    "data_2021 = pd.read_csv('data/2021.csv')\n",
    "data_2022 = pd.read_csv('data/2022.csv')\n",
    "\n",
    "print(data_2020.columns)\n",
    "print(data_2020.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramme\n",
    "\n",
    "data_2020 = data_2020.sort_values(by='Ladder score', ascending=False)\n",
    "fig = px.bar(\n",
    "    data_2020,\n",
    "    x='Country name',\n",
    "    y='Ladder score',\n",
    "    title='Histogramme du score de bonheur par pays en 2020',\n",
    "    color='Regional indicator'\n",
    ")\n",
    "fig.update_xaxes(categoryorder='total descending')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric = data_2020[['Ladder score', 'Logged GDP per capita', 'Social support', 'Healthy life expectancy', 'Freedom to make life choices','Perceptions of corruption', 'Generosity']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carte chloropèthe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carte \n",
    "carte = px.choropleth(\n",
    "    data_2020,\n",
    "    locations='Country name',\n",
    "    locationmode='country names',\n",
    "    color='Ladder score',\n",
    "    title='Carte du score de bonheur par pays en 2020',\n",
    "    color_continuous_scale='thermal',\n",
    ")\n",
    "carte.update_geos(showframe=False, showcoastlines=False)\n",
    "carte.update_layout(margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0})\n",
    "carte.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix\n",
    "\n",
    "correlation_matrix = df_numeric.corr()\n",
    "\n",
    "# Create the heatmap\n",
    "fig = px.imshow(\n",
    "    correlation_matrix,\n",
    "    title=\"Correlation Heatmap\",\n",
    "    labels=dict(x=\"Columns\", y=\"Columns\", color=\"Correlation\"),\n",
    "    color_continuous_scale=\"RdBu\",\n",
    "    zmin=-1, zmax=1, text_auto=True\n",
    ")\n",
    "fig.update_layout(width=900, height=800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardisation du df\n",
    "\n",
    "df_standardise = (df_numeric - df_numeric.mean()) / df_numeric.std()\n",
    "\n",
    "print(df_standardise.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# ACP sur donnees standardisees\n",
    "\n",
    "pca = PCA(n_components=2)  # Choisissez le nombre de composantes souhaité\n",
    "principal_components = pca.fit_transform(df_standardise)\n",
    "principal_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])\n",
    "principal_df[['Country name','Regional indicator', 'Ladder score', 'Generosity', 'Social support', 'Logged GDP per capita', 'Healthy life expectancy', 'Freedom to make life choices', 'Perceptions of corruption']] = data_2020[['Country name','Regional indicator', 'Ladder score', 'Generosity', 'Social support', 'Logged GDP per capita', 'Healthy life expectancy', 'Freedom to make life choices', 'Perceptions of corruption']]\n",
    "\n",
    "\n",
    "# Visualisation\n",
    "fig = px.scatter(\n",
    "    principal_df, \n",
    "    template='plotly_white',\n",
    "    x='PC1', \n",
    "    y=\"PC2\", \n",
    "    hover_name='Country name',  # Le nom principal affiché\n",
    "    color='Regional indicator',  # Couleur basée sur cette colonne\n",
    "    hover_data={ \n",
    "        'Country name': False,  # Masquer ces colonnes\n",
    "        'Regional indicator': False,\n",
    "        'Ladder score': True,\n",
    "        'Generosity': True,\n",
    "        'Social support': True,\n",
    "        'Logged GDP per capita': True,\n",
    "        'Healthy life expectancy': True,\n",
    "        'Freedom to make life choices': True,\n",
    "        'Perceptions of corruption': True\n",
    "    },\n",
    "    color_discrete_sequence=px.colors.qualitative.G10,\n",
    ")\n",
    "fig.update_traces(marker=dict(size=8))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score silhouette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardisation des données\n",
    "scaler = StandardScaler()\n",
    "df_standardise = scaler.fit_transform(df_numeric)\n",
    "\n",
    "# Liste pour stocker les scores de silhouette\n",
    "silhouette_scores = []\n",
    "\n",
    "# Tester de 2 à 10 clusters\n",
    "for n_clusters in range(2, 11):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    kmeans.fit(df_standardise)  # ou df_numeric\n",
    "    score = silhouette_score(df_standardise, kmeans.labels_)\n",
    "    silhouette_scores.append(score)\n",
    "\n",
    "# Affichage des scores de silhouette\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=list(range(2, 11)),\n",
    "    y=silhouette_scores,\n",
    "    mode='lines+markers',\n",
    "    name='Silhouette Score',\n",
    "    line=dict(color='blue'),\n",
    "    marker=dict(size=8)\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Méthode de la silhouette pour KMeans',\n",
    "    xaxis_title='Nombre de clusters',\n",
    "    yaxis_title='Indice de silhouette moyen',\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "#choix du nombre de cluster \n",
    "max_silhouette_score = max(silhouette_scores)\n",
    "n_clusters = silhouette_scores.index(max_silhouette_score) + 2\n",
    "\n",
    "n_clusters \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering avec K-Means\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)  # 3 clusters par exemple\n",
    "kmeans.fit(df_standardise)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Ajout des labels au dataframe\n",
    "principal_df['cluster'] = labels\n",
    "\n",
    "# Convertir les clusters en type catégoriel pour légende continue\n",
    "principal_df[\"cluster\"] = principal_df[\"cluster\"].astype(str)\n",
    "\n",
    "# Visualisation\n",
    "fig_kmeans = px.scatter(\n",
    "    template='plotly_white',\n",
    "    data_frame=principal_df, \n",
    "    x='PC1', \n",
    "    y='PC2', \n",
    "    color='cluster', \n",
    "    hover_name='Country name',\n",
    "    color_discrete_sequence=px.colors.qualitative.G10,\n",
    ")\n",
    "# Cacher la légende\n",
    "fig_kmeans.update_layout(showlegend=False)\n",
    "fig_kmeans.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajouter les centroïdes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un DataFrame des centroïdes avec les noms de colonnes\n",
    "centroids_df = pd.DataFrame(kmeans.cluster_centers_, columns=df_numeric.columns)\n",
    "\n",
    "# Appliquer la transformation PCA\n",
    "centroids_pca = pca.transform(centroids_df)  # Utiliser un DataFrame avec les mêmes colonnes\n",
    "\n",
    "# Convertir en DataFrame pour manipulation\n",
    "centroids_pca_df = pd.DataFrame(centroids_pca, columns=['PC1', 'PC2'])\n",
    "centroids_pca_df['cluster'] = range(n_clusters)  # Ajouter les étiquettes des clusters\n",
    "\n",
    "# Visualisation des clusters avec les centroïdes\n",
    "fig_kmeans = px.scatter(\n",
    "    data_frame=principal_df, \n",
    "    x='PC1', \n",
    "    y='PC2', \n",
    "    color='cluster', \n",
    "    hover_name='Country name',\n",
    "    color_discrete_sequence=px.colors.qualitative.G10,\n",
    "    title=\"Clusters avec les Centroïdes\"\n",
    ")\n",
    "\n",
    "# Ajouter les centroïdes comme points distincts\n",
    "fig_kmeans.add_trace(\n",
    "    go.Scatter(\n",
    "        x=centroids_pca_df['PC1'],\n",
    "        y=centroids_pca_df['PC2'],\n",
    "        mode='markers',\n",
    "        marker=dict(size=12, color='black', symbol='x'),\n",
    "        name='Centroïdes'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Affichage final\n",
    "fig_kmeans.update_layout(template=\"plotly_white\", showlegend=True)\n",
    "fig_kmeans.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Mixture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Silhouette Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste pour stocker les scores de silhouette\n",
    "silhouette_scores_gmm = []\n",
    "\n",
    "# Tester de 2 à 10 clusters\n",
    "for n_clusters in range(2, 11):\n",
    "    gmm = GaussianMixture(n_components=n_clusters, random_state=42)\n",
    "    gmm.fit(df_standardise)  # ou df_numeric\n",
    "    labels = gmm.predict(df_standardise)\n",
    "    score = silhouette_score(df_standardise, labels)\n",
    "    silhouette_scores_gmm.append(score)\n",
    "\n",
    "# Création du graphique avec Plotly\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=list(range(2, 11)),\n",
    "    y=silhouette_scores_gmm,\n",
    "    mode='lines+markers',\n",
    "    name='Silhouette Score',\n",
    "    line=dict(color='red'),\n",
    "    marker=dict(size=8)\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Méthode de la silhouette pour GMM',\n",
    "    xaxis_title='Nombre de clusters',\n",
    "    yaxis_title='Indice de silhouette moyen',\n",
    "    template='plotly_white'  # Utiliser le thème blanc\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "max_silhouette_score = max(silhouette_scores_gmm)\n",
    "n_clusters = silhouette_scores_gmm.index(max_silhouette_score) + 2\n",
    "\n",
    "n_clusters \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standardisation des données\n",
    "scaler = StandardScaler()\n",
    "df_standardise = scaler.fit_transform(df_numeric)\n",
    "\n",
    "# Clustering avec Gaussian Mixture\n",
    "gmm = GaussianMixture(n_components=n_clusters, random_state=42)  # 3 clusters par exemple\n",
    "gmm.fit(df_standardise)\n",
    "labels = gmm.predict(df_standardise)\n",
    "\n",
    "# Ajout des labels au dataframe\n",
    "principal_df['cluster'] = labels\n",
    "\n",
    "# Convertir les clusters en type catégoriel pour légende continue\n",
    "principal_df[\"cluster\"] = principal_df[\"cluster\"].astype(str)\n",
    "\n",
    "# Visualisation\n",
    "fig = px.scatter(\n",
    "    template='plotly_white',\n",
    "    data_frame=principal_df, \n",
    "    x='PC1', \n",
    "    y='PC2', \n",
    "    color='cluster', \n",
    "    hover_name='Country name',\n",
    "    color_discrete_sequence=px.colors.qualitative.G10,\n",
    ")\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avec les centroïdes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "import numpy as np\n",
    "\n",
    "# Calcul des centroïdes des clusters à partir des moyennes de GMM\n",
    "gmm_centroids = pd.DataFrame(gmm.means_, columns=df_numeric.columns)  # Moyennes des clusters\n",
    "\n",
    "# Appliquer la transformation PCA sur les centroïdes\n",
    "centroids_pca_gmm = pca.transform(gmm_centroids)\n",
    "\n",
    "# Créer un DataFrame pour les centroïdes projetés\n",
    "centroids_pca_gmm_df = pd.DataFrame(centroids_pca_gmm, columns=['PC1', 'PC2'])\n",
    "centroids_pca_gmm_df['cluster'] = range(n_clusters)  # Ajouter les étiquettes des clusters\n",
    "\n",
    "# Visualisation des clusters GMM avec les centroïdes\n",
    "fig_gmm = px.scatter(\n",
    "    data_frame=principal_df, \n",
    "    x='PC1', \n",
    "    y='PC2', \n",
    "    color='cluster', \n",
    "    hover_name='Country name',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    "    title=\"Clusters avec les Centroïdes (Gaussian Mixture)\"\n",
    ")\n",
    "\n",
    "# Ajouter les centroïdes comme points distincts\n",
    "fig_gmm.add_trace(\n",
    "    go.Scatter(\n",
    "        x=centroids_pca_gmm_df['PC1'],\n",
    "        y=centroids_pca_gmm_df['PC2'],\n",
    "        mode='markers',\n",
    "        marker=dict(size=12, color='black', symbol='x'),\n",
    "        name='Centroïdes'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Affichage final\n",
    "fig_gmm.update_layout(template=\"plotly_white\", showlegend=True)\n",
    "fig_gmm.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consensus clustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avec les deux méthodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.cluster import SpectralClustering\n",
    "import plotly.express as px\n",
    "\n",
    "# 1. Générer un jeu de données pour l'exemple (remplacer par vos propres données)\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "df_standardise = make_blobs(n_samples=300, centers=3, random_state=42)[0]\n",
    "\n",
    "# Standardisation des données\n",
    "scaler = StandardScaler()\n",
    "df_standardise = scaler.fit_transform(df_standardise)\n",
    "\n",
    "# 2. Appliquer K-Means\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "kmeans_labels = kmeans.fit_predict(df_standardise)\n",
    "\n",
    "# 3. Appliquer Gaussian Mixture Models (GMM)\n",
    "gmm = GaussianMixture(n_components=3, random_state=42)\n",
    "gmm_labels = gmm.fit_predict(df_standardise)\n",
    "\n",
    "# 4. Construction de la matrice de consensus\n",
    "n_samples = df_standardise.shape[0]\n",
    "n_iterations = 2  # Nombre de méthodes de clustering\n",
    "\n",
    "C = np.zeros((n_samples, n_samples))  # Matrice de consensus initialisée à 0\n",
    "\n",
    "# Comparaison des labels pour K-Means et GMM\n",
    "for i in range(n_samples):\n",
    "    for j in range(i + 1, n_samples):\n",
    "        if kmeans_labels[i] == kmeans_labels[j]:\n",
    "            C[i, j] += 1\n",
    "            C[j, i] += 1\n",
    "        if gmm_labels[i] == gmm_labels[j]:\n",
    "            C[i, j] += 1\n",
    "            C[j, i] += 1\n",
    "\n",
    "# Normaliser la matrice de consensus\n",
    "C = C / n_iterations\n",
    "\n",
    "# 5. Créer la matrice de distance (en évitant les divisions par 0)\n",
    "distance_matrix = 1 / (C + np.eye(n_samples))  # Ajout de l'identité pour éviter division par zéro\n",
    "distance_matrix[np.isinf(distance_matrix)] = 0  # Remplacer les infinis par 0\n",
    "distance_matrix[np.isnan(distance_matrix)] = 0  # Remplacer les NaN par 0\n",
    "\n",
    "# 6. Appliquer Spectral Clustering sur la matrice de distance\n",
    "spectral = SpectralClustering(n_clusters=3, affinity='precomputed', random_state=42)\n",
    "final_labels = spectral.fit_predict(distance_matrix)\n",
    "\n",
    "# 7. Visualisation avec Plotly\n",
    "# Convertir les données en DataFrame pour une meilleure gestion avec Plotly\n",
    "principal_df = pd.DataFrame(df_standardise, columns=[\"PC1\", \"PC2\"])\n",
    "principal_df['cluster'] = final_labels\n",
    "\n",
    "# Visualisation avec Plotly\n",
    "fig = px.scatter(\n",
    "    principal_df,\n",
    "    x='PC1', \n",
    "    y='PC2', \n",
    "    color='cluster',\n",
    "    title=\"Clustering Consensuel avec K-Means et GMM\",\n",
    "    labels={'cluster': 'Cluster'},\n",
    "    color_continuous_scale=\"Viridis\"\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    template=\"plotly_white\",  # Fond blanc pour un look propre\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering DBSCAN\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardisation des données\n",
    "scaler = StandardScaler()\n",
    "df_standardise = scaler.fit_transform(df_numeric)\n",
    "\n",
    "# Clustering\n",
    "dbscan = DBSCAN(eps=1.5, min_samples=2)\n",
    "dbscan.fit(df_standardise)\n",
    "labels = dbscan.labels_\n",
    "\n",
    "# Ajout des labels au dataframe\n",
    "principal_df['cluster'] = labels\n",
    "\n",
    "# Convertir les clusters en type catégoriel pour légende continue\n",
    "principal_df[\"cluster\"] = principal_df[\"cluster\"].astype(str)\n",
    "\n",
    "# Visualisation\n",
    "\n",
    "fig = px.scatter(\n",
    "    template='plotly_white',\n",
    "    data_frame= principal_df, \n",
    "    x='PC1', \n",
    "    y='PC2', \n",
    "    color='cluster', \n",
    "    hover_name='Country name',\n",
    "    color_discrete_sequence=px.colors.qualitative.G10,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
